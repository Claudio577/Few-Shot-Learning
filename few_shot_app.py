import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np

# Definindo o dispositivo (CPU ou GPU) - Foco no uso eficiente
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==============================================================
# 1. FUN√á√ÉO: CARREGAR O MODELO (FEATURE EXTRACTOR)
# ==============================================================
@st.cache_resource # Cacheia o modelo para n√£o recarregar a cada intera√ß√£o
def load_feature_extractor():
    # Usamos o MobileNetV2 (pequeno e eficiente) pr√©-treinado no ImageNet
    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
    
    # ‚ö†Ô∏è A chave do FSL √© remover a √∫ltima camada (classificador)
    # para usar a pen√∫ltima camada como nosso Feature Extractor (embedding)
    model.classifier = nn.Identity() # Remove a camada de classifica√ß√£o
    
    # Coloca o modelo em modo de avalia√ß√£o (importante para modelos pr√©-treinados)
    model.eval()
    model.to(DEVICE)
    st.info(f"üß† Modelo MobileNetV2 carregado com sucesso no {DEVICE.type}!")
    return model

# ==============================================================
# 2. FUN√á√ÉO: PROCESSAR IMAGEM E GERAR EMBEDDING (VETOR)
# ==============================================================
def preprocess_and_embed(image: Image.Image, model: nn.Module) -> np.ndarray:
    # ‚öôÔ∏è Transforma√ß√µes necess√°rias para MobileNet
    transform = transforms.Compose([
        transforms.Resize((224, 224)), # Redimensiona (padr√£o 224x224 para MobileNet)
        transforms.ToTensor(),         # Converte para tensor
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normaliza√ß√£o ImageNet
    ])

    # 1. Pr√©-processamento
    input_tensor = transform(image).unsqueeze(0).to(DEVICE) # Adiciona a dimens√£o do lote (batch)

    # 2. Gera√ß√£o do Embedding
    with torch.no_grad():
        embedding_tensor = model(input_tensor)
        
    # Converte o tensor para um array NumPy para facilitar os c√°lculos de dist√¢ncia
    return embedding_tensor.cpu().numpy().flatten()

# ==============================================================
# 3. FUN√á√ÉO: CALCULAR A DIST√ÇNCIA DE SIMILARIDADE
# ==============================================================
def calculate_similarity(embedding_a: np.ndarray, embedding_b: np.ndarray) -> float:
    # üìè Dist√¢ncia Coseno √© a m√©trica padr√£o para similaridade de embeddings
    # Quanto mais pr√≥ximo de 1, mais similares s√£o.
    
    dot_product = np.dot(embedding_a, embedding_b)
    norm_a = np.linalg.norm(embedding_a)
    norm_b = np.linalg.norm(embedding_b)
    
    if norm_a == 0 or norm_b == 0:
        return 0.0 # Evita divis√£o por zero
        
    cosine_similarity = dot_product / (norm_a * norm_b)
    return float(cosine_similarity) # Retorna um float simples
